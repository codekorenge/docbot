[App]
name = { prototype docbot }
data = ../data
metadata = ../metadata
progress = False
verbose = True
prompts = ../prompts/

[Embed]
name = BAAI/bge-base-en-v1.5

[LLM]
name = llama3.1
token_limit=2000
temperature=0.1
# add context_length - so prompt can be within the size.

[Chunk]
size = 200
overlap = 10

[Retriever]
max = 10
score = 0.55

[Generator]
# move token_limit here (it is more relevant to generation)! token_limit < context_length


